# -*- coding: utf-8 -*-
"""Pytorch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vvUjaZp4O6zbkaDWGLxxSay8aQObsc-T

# Basics
- create a basic FNN
"""

# !pip install torch

import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets
from torchvision.transforms import ToTensor

if __name__ =="__main__":

  def download_datasets():
    train_data = datasets.MNIST(
        root="data",
        download=True ,#if not downloaded then download
        train=True, #I am interested in trainset of the data
        transform=ToTensor()#reshapes the new tensor to get the value between 0-1
    )

    test_data = datasets.MNIST(
        root="data",
        download = True,
        train=False,
        transform=ToTensor()
    )
    return train_data, test_data

  train_data, test_data = download_datasets()


  """we have now downloaded the dataset

  ### Dataloader
  - an iterable, because it allows us to load my data in batches
  """

  train_DataLoader = DataLoader(
      train_data,
      batch_size = 128
  )
  test_DataLoader = DataLoader(
      test_data,
      batch_size = 128
  )

  # !!concept!!
  for image, label in train_DataLoader:
    print(image[0].shape)
    print(label[0].item())
    break

  # !!concept!!
  # len(train_DataLoader)
  # 60000/128

  """### Network"""

  class FeedForward(nn.Module): #inherit from Module
  #define the layers in init
    def __init__(self):
      super().__init__()
      self.flatten = nn.Flatten()
      self.dense_layers = nn.Sequential(
          nn.Linear(28*28, 256),
          nn.ReLU(),
          nn.Linear(256,10) # I have 10 classes
      )
      self.softmax = nn.Softmax(dim=1)

  # Define the forward path of my data
    def forward(self, inp_data):
      flattened_data = self.flatten(inp_data)
      logits = self.dense_layers(flattened_data)
      predictions = self.softmax(logits)
      return predictions

  """#### Device"""

  if torch.cuda.is_available():
    device = "cuda"
  else:
    device ="cpu"


  feed_fwd_net = FeedForward().to(device)

  """### Training"""

  def train_one_epoch(model, data_loader, loss_func, optimizer, device):

    for data, label in data_loader:

      #model and label needs to be in same device
      data,label = data.to(device), label.to(device)

      #loss
      predictions = model(data)
      loss = loss_func(predictions, label)

      #back propogation to calulate grad decent to update the weights
      optimizer.zero_grad()     #... to reset the gradients
      loss.backward()           #... calculate the gradients
      optimizer.step()          #... Update the weights

    print(f"Loss = {loss.item()}")

  def train(model, data_loader, loss_func, optimizer, device, epochs):
    for i in range(epochs):
      print(f"Epoch {i+1}  =", train_one_epoch(model, data_loader, loss_func, optimizer, device))

  # feed_fwd_net = FeedForward().to(device)   #...model
  # train_DataLoader
  loss_func = nn.CrossEntropyLoss()
  optimizer = torch.optim.Adam(feed_fwd_net.parameters(), lr=0.01)
  #device
  epochs = 10
  train(feed_fwd_net, train_DataLoader,loss_func, optimizer, device, epochs)

  torch.save(feed_fwd_net.state_dict(), "feed_fwd_net.pth")
  print("saved")


